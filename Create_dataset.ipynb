{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "# input: dataframe\n",
    "# output: dataframe\n",
    "# filter_outliers: remove top % stays\n",
    "def data_formating(file_name, filter_outliers=True):\n",
    "    icu_df = pd.read_csv(file_name)\n",
    "    \n",
    "    # data cleaning\n",
    "    icu_df = icu_df.astype({'outcome_time':'datetime64[ns]','recorded_time':'datetime64[ns]'})\n",
    "    icu_df = icu_df.replace({'Female':1,'Male':0})\n",
    "    icu_df1 = icu_df.copy()\n",
    "    \n",
    "    adm_t = icu_df1.groupby('dummy_encounter_id')['recorded_time'].aggregate('min')\n",
    "    proxyend = icu_df1.groupby('dummy_encounter_id')['outcome_time'].aggregate('min')\n",
    "    first_m = adm_t\n",
    "    # admission time round down to nearest hour\n",
    "    adm_t = (adm_t.astype('int') - adm_t.astype('int')%(60*60*10**9)).astype('datetime64[ns]')\n",
    "    # outcome time round down to nearest hour\n",
    "    proxyend = (proxyend.astype('int') - proxyend.astype('int')%(60*60*10**9)).astype('datetime64[ns]')\n",
    "    \n",
    "    # concate\n",
    "    #\n",
    "    icu_df2 = pd.merge(proxyend,icu_df1, left_index=True,right_on='dummy_encounter_id')\n",
    "    icu_df2 = icu_df2.rename(columns={'outcome_time_x':'proxyend_time','outcome_time_y':'outcome_time'})\n",
    "    #\n",
    "    icu_df2 = pd.merge(adm_t,icu_df2, left_index=True,right_on='dummy_encounter_id')\n",
    "    icu_df2 = icu_df2.rename(columns={'recorded_time_x':'adm_time','recorded_time_y':'recorded_time'})\n",
    "    #\n",
    "    icu_df2 = pd.merge(first_m,icu_df2, left_index=True,right_on='dummy_encounter_id')\n",
    "    icu_df2 = icu_df2.rename(columns={'recorded_time_x':'first_m','recorded_time_y':'recorded_time'})\n",
    "\n",
    "    # calculate los (original los)\n",
    "    #icu_df2['los'] = icu_df2['outcome_time']-icu_df2['adm_time']\n",
    "    icu_df2['los'] = icu_df2['outcome_time']-icu_df2['first_m']\n",
    "    \n",
    "    icu_df2 = icu_df2.drop(columns=['first_m'])\n",
    "\n",
    "    \n",
    "    # filter out top 1% longest stay\n",
    "    if filter_outliers:\n",
    "        los_table = icu_df2.groupby('dummy_encounter_id').first()[['outcome','los']]\n",
    "        los_table['los'] = los_table['los'].astype('timedelta64[h]')\n",
    "        ninty_nine_quantile = los_table['los'].quantile(q=0.99,interpolation='lower')\n",
    "        icu_df2['los'] = icu_df2['los'].astype('timedelta64[h]')\n",
    "        icu_df2 = icu_df2[icu_df2['los']<=ninty_nine_quantile]\n",
    "    \n",
    "    return icu_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 24 hours of data from each encounter\n",
    "# input: orinigal dataframe\n",
    "# output: dataframe of 24 hours of data for each encounter\n",
    "# start: \"first\": first 24 hours; \"last\": 24 hours xx hour before event; \"random\": random 24hours\n",
    "# dt_end: window period before event\n",
    "\n",
    "def slicing(df,start,duration=24,dt_end=12):\n",
    "    #eligable\n",
    "    icu_df = df[df['los']>=(duration+dt_end)]\n",
    "    print('after slicing: ', len(icu_df['dummy_encounter_id'].unique()))\n",
    "    # first 00hrs\n",
    "    if start == 'first':\n",
    "        icu_df['sample_start'] = icu_df['adm_time']\n",
    "        icu_df = icu_df[(icu_df['recorded_time'] < (icu_df['sample_start'] + pd.Timedelta(hours=duration)))]\n",
    "        icu_df = icu_df.sort_values(by=['dummy_encounter_id','recorded_time'])\n",
    "    # last 00hrs\n",
    "    elif start == 'last':\n",
    "        icu_df['sample_start'] = icu_df['proxyend_time']- pd.Timedelta(hours=duration+dt_end)\n",
    "        icu_df = icu_df[(icu_df['recorded_time']>= icu_df['sample_start'])\n",
    "                         & (icu_df['recorded_time']< (icu_df['sample_start']+ pd.Timedelta(hours=duration)))]\n",
    "        icu_df = icu_df.sort_values(by=['dummy_encounter_id','recorded_time'])\n",
    "    # random slice\n",
    "    elif start == 'random':\n",
    "        # split into survival and outcome group\n",
    "        icu_o = icu_df[icu_df['outcome']==1]\n",
    "        icu_s = icu_df[icu_df['outcome']==0]\n",
    "        \n",
    "        # last 00hrs before 00hrs from outcomes for outcome groups\n",
    "        icu_o['sample_start'] = icu_o['proxyend_time']- pd.Timedelta(hours=duration+dt_end)\n",
    "        icu_o = icu_o[(icu_o['recorded_time']>= icu_o['sample_start'])\n",
    "                       &(icu_o['recorded_time']< (icu_o['sample_start']+ pd.Timedelta(hours=duration)))]\n",
    "        icu_o = icu_o.sort_values(by=['dummy_encounter_id','recorded_time'])\n",
    "        \n",
    "        # random slice before 00hrs from outcomes for survival groups\n",
    "        icu_st = icu_s.groupby('dummy_encounter_id').first()\n",
    "        icu_st['upper_bound'] = icu_st['proxyend_time'] - pd.Timedelta(hours=(duration+dt_end))\n",
    "        icu_st['gap_unit'] = (icu_st['upper_bound'] - icu_st['adm_time'] )/pd.Timedelta(minutes=60)\n",
    "        \n",
    "        #Randomly draw start time of slices\n",
    "        sample_start = []\n",
    "        np.random.seed(0)\n",
    "        for i,unit in enumerate(icu_st['gap_unit'].to_list()):\n",
    "            try:\n",
    "                starttime = icu_st['adm_time'].iloc[i] + np.random.choice(int(unit+1))*pd.Timedelta(minutes=60)\n",
    "            except:\n",
    "                print(unit)\n",
    "                starttime = icu_st['adm_time'].iloc[i]\n",
    "            sample_start.append(starttime)\n",
    "        icu_st['sample_start'] = sample_start\n",
    "        print('before concate; ', len(icu_st.index))\n",
    "        icu_sm = pd.merge(icu_s,icu_st['sample_start'],right_index=True,left_on='dummy_encounter_id')\n",
    "        print('after concate; ', len(icu_sm['dummy_encounter_id'].unique()))\n",
    "        #slice\n",
    "        icu_sm = icu_sm[(icu_sm['recorded_time']>=icu_sm['sample_start'])\n",
    "                                &(icu_sm['recorded_time']<icu_sm['sample_start']+pd.Timedelta(hours=duration))]\n",
    "        icu_sm = icu_sm.sort_values(by=['dummy_encounter_id','recorded_time'])\n",
    "        print('after slicing; ', len(icu_sm['dummy_encounter_id'].unique()))\n",
    "        #concat survival and outcome table\n",
    "        icu_df = pd.concat([icu_o,icu_sm])\n",
    "        \n",
    "    return icu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Configurate\n",
    "# input: dataframe of 24 hours of data for each encounter\n",
    "# output: samples with selected features\n",
    "def transformer(df,dummies = True, j_block=15,base=True,vitals=True,comments=True,v_set=False,medication=False,notes=False,n_extract=False):\n",
    "    if base:\n",
    "        base=[\n",
    "        'dummy_encounter_id',\n",
    "            'adm_time',\n",
    "         'dt_start',\n",
    "         'outcome',\n",
    "         'julian_minute_c']\n",
    "    else: base=[]\n",
    "        \n",
    "    if vitals:\n",
    "        vitals = [\n",
    "         'hr_entered',\n",
    "         'rr_entered',\n",
    "         'bp_entered',\n",
    "         'temp_entered',\n",
    "         'spo2_entered']\n",
    "    else: vitals=[]\n",
    "        \n",
    "    if comments:\n",
    "        comments = [\n",
    "         'hr_comment',\n",
    "         'rr_comment',\n",
    "         'bp_comment',\n",
    "         'temp_comment',\n",
    "         'spo2_comment']\n",
    "    else: comments=[]\n",
    "        \n",
    "    if v_set:\n",
    "        v_set = [\n",
    "         'one_vital',\n",
    "         'set_vital']\n",
    "    else: v_set=[]\n",
    "        \n",
    "    if medication:\n",
    "        medication = [\n",
    "         'prn',\n",
    "         'withheld']\n",
    "    else: medication=[]\n",
    "        \n",
    "    if notes:\n",
    "        notes = [\n",
    "         'notes']\n",
    "    else: notes=[]\n",
    "        \n",
    "    if n_extract:\n",
    "        n_extract=[\n",
    "         'Fall down',\n",
    "         'Abnormal rate rhythm depth and effort of respirations',\n",
    "         'Abnormal Mental State',\n",
    "         'Communication problem',\n",
    "         'cognitive defects',\n",
    "         'Impaired blood oxygen',\n",
    "         'Delusions',\n",
    "         'General concern',\n",
    "         'Hallucinations',\n",
    "         'Chest Pain',\n",
    "         'Mood disorder',\n",
    "         'Abnormal Blood Pressure',\n",
    "         'Abnormal Heart Rhythm',\n",
    "         'Weight alteration',\n",
    "         'Improper renal function',\n",
    "         'abnormal rate rhythm depth and effort of respirations_1',\n",
    "         'Violence Gesture',\n",
    "         'Abnormal lab test',\n",
    "         'Restraint',\n",
    "         'Aspiration',\n",
    "         'Suicide Risk',\n",
    "         'Abnormal Temperature',\n",
    "         'Monitoring',\n",
    "         'Incisional pain',\n",
    "         'cranial nerve palsies',\n",
    "         'Musculoskeletal Pain',\n",
    "         'Sign Symptoms of infection',\n",
    "         'ataxic patterns',\n",
    "         'hypocalcemia',\n",
    "         'seizure',\n",
    "         'pain duration',\n",
    "         'Diagnosis related with Infection',\n",
    "         'Improper Airway Clearance',\n",
    "         'abnormal reflex',\n",
    "         'Acute onset pain',\n",
    "         'Abuse',\n",
    "         'Localized pain',\n",
    "         'pain killer',\n",
    "         'Back Pain',\n",
    "         'Fluid Volume Alteration',\n",
    "         'Dysuria',\n",
    "         'Arthralgia',\n",
    "         'delirium',\n",
    "         'Cutaneous Pain',\n",
    "         'Oxygen response',\n",
    "         'headache',\n",
    "         'Medication related with Infection']\n",
    "    else: n_extract=[]\n",
    "\n",
    "    \n",
    "    columns = base+vitals+comments+v_set+medication+notes+ n_extract\n",
    "    \n",
    "    # Calculate julian time\n",
    "    df['julian_time'] = df['recorded_time'].dt.time\n",
    "\n",
    "    a = list(df['julian_time'])\n",
    "    minute_c = []\n",
    "    for i in tqdm_notebook(a):\n",
    "        h,m,s = str(i).split(':')\n",
    "        count = (int(h)*60 + int(m))\n",
    "        \n",
    "        minute_c.append(count)\n",
    "\n",
    "    # julian minute_c\n",
    "    df['julian_minute_c'] = minute_c\n",
    "    # calculate measurement time to sample start time\n",
    "    df['dt_start'] = df['recorded_time'] - df['sample_start']\n",
    "\n",
    "    # select columns\n",
    "    cleaned = df.loc[:,columns]\n",
    "    \n",
    "    # create Time-of-date variables\n",
    "    cleaned['jblock'] = pd.cut(cleaned.julian_minute_c,range(0,1441,j_block),right=False)\n",
    "    if dummies:\n",
    "        cleaned = pd.get_dummies(cleaned,prefix=['jblock'])\n",
    "        \n",
    "    \n",
    "    #check number\n",
    "    outcome = len(cleaned[cleaned['outcome']==1]['dummy_encounter_id'].unique())\n",
    "    survival = len(cleaned[cleaned['outcome']==0]['dummy_encounter_id'].unique())\n",
    "    print('with columns: ', columns)\n",
    "    print('outcome group: ', outcome)\n",
    "    print('survival group: ', survival)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "# partitioned dataset into regularly spaced timesteps and converted the sequences of each features into a vector of binary variables.\n",
    "# input: samples with selected features\n",
    "# output: training data, training lable, holdout data, holdout lable (np.array of binary variables)\n",
    "# freq: length of timestep (minutes)\n",
    "def create_dataset(dataset, freq=15):\n",
    "    periods = int(1440/freq)\n",
    "    freq = str(freq)+'T'\n",
    "    # create time base table,  freq min for one step\n",
    "    Frame = pd.DataFrame(0,columns=dataset.columns, index=pd.timedelta_range(0, periods=periods, freq=freq))\n",
    "    Frame = Frame.drop(columns=['dummy_encounter_id','adm_time','outcome','julian_minute_c','dt_start'])\n",
    "    #print(periods)\n",
    "    \n",
    "    # split dataset into training and holdout set by predefined time\n",
    "    ticu_stay = dataset[dataset['adm_time']<pd.to_datetime('2016-02-01')]['dummy_encounter_id'].unique()\n",
    "    hicu_stay = dataset[dataset['adm_time']>=pd.to_datetime('2016-02-01')]['dummy_encounter_id'].unique()\n",
    "    \n",
    "    tseqs = []\n",
    "    tlabels = []\n",
    "    \n",
    "    #n = 0\n",
    "    #loop thru icu stays, training \n",
    "    for idx in tqdm_notebook(ticu_stay):\n",
    "        df_time = dataset[dataset['dummy_encounter_id']==idx]\n",
    "        label = df_time['outcome'].unique()[0]\n",
    "        df_time = df_time.drop(columns=['dummy_encounter_id','adm_time','outcome','julian_minute_c'])\n",
    "        df_time = df_time.set_index('dt_start')\n",
    "        \n",
    "        \n",
    "        #concat with base table\n",
    "        df_time = pd.concat([Frame,df_time])\n",
    "        df_time = df_time.resample(freq).sum()\n",
    "     \n",
    "        # collapse count within each timesteps to 1\n",
    "        df_time.iloc[:,:-1] = df_time.iloc[:,:-1] != 0\n",
    "        #n+=1\n",
    "        n_features = len(df_time.columns)\n",
    "        #print(n_features)\n",
    "        try:\n",
    "            assert df_time.to_numpy(dtype='float64').shape == (periods,n_features)\n",
    "        except:\n",
    "            print(idx, df_time.to_numpy(dtype='float64').shape)\n",
    "        tlabels.append(label)\n",
    "        \n",
    "        seq = df_time.to_numpy(dtype='float64')\n",
    "        \n",
    "        # impute Time-of-day variables\n",
    "        #find first row with jb\n",
    "        ss = df_time.iloc[:,-periods:]\n",
    "        st = ss[ss.any(axis=1)].index[0]\n",
    "        i = ss.index.get_loc(st)\n",
    "        #find first col with jb\n",
    "        z = ss.iloc[i,:]!=0\n",
    "        js = z[z==True].index[0]\n",
    "        j = ss.columns.get_loc(js)\n",
    "        \n",
    "        col = (j-i)\n",
    "        rows = [n for n in range(periods)]\n",
    "        cols = [(col+n)%periods for n in range(periods)]\n",
    "        p = np.zeros((periods,periods))\n",
    "        p[rows,cols]=1\n",
    "        seq[:,-periods:] = p\n",
    "        tseqs.append(seq)\n",
    "        #\n",
    "        \n",
    "    \n",
    "    hseqs = []\n",
    "    hlabels = []\n",
    "    #loop thru icu stays, holdout \n",
    "    for idx in tqdm_notebook(hicu_stay):\n",
    "        df_time = dataset[dataset['dummy_encounter_id']==idx]\n",
    "        label = df_time['outcome'].unique()[0]\n",
    "        df_time = df_time.drop(columns=['dummy_encounter_id','adm_time','outcome','julian_minute_c'])\n",
    "        df_time = df_time.set_index('dt_start')\n",
    "        \n",
    "        \n",
    "        #concat with floor table\n",
    "        df_time = pd.concat([Frame,df_time])\n",
    "        df_time = df_time.resample(freq).sum()\n",
    "     \n",
    "        # collapse count within each time lapse to 1\n",
    "        df_time.iloc[:,:-1] = df_time.iloc[:,:-1] != 0\n",
    "        #n+=1\n",
    "        n_features = len(df_time.columns)\n",
    "        #print(n_features)\n",
    "        try:\n",
    "            assert df_time.to_numpy(dtype='float64').shape == (periods,n_features)\n",
    "        except:\n",
    "            print(idx, df_time.to_numpy(dtype='float64').shape)\n",
    "        hlabels.append(label)\n",
    "        seq = df_time.to_numpy(dtype='float64')\n",
    "        # imput julian timesteps\n",
    "        #find first row with jb\n",
    "        ss = df_time.iloc[:,-periods:]\n",
    "        st = ss[ss.any(axis=1)].index[0]\n",
    "        i = ss.index.get_loc(st)\n",
    "        #find first col with jb\n",
    "        z = ss.iloc[i,:]!=0\n",
    "        js = z[z==True].index[0]\n",
    "        j = ss.columns.get_loc(js)\n",
    "        #print(i,j)\n",
    "        col = (j-i)\n",
    "        rows = [n for n in range(periods)]\n",
    "        cols = [(col+n)%periods for n in range(periods)]\n",
    "        p = np.zeros((periods,periods))\n",
    "        p[rows,cols]=1\n",
    "        seq[:,-periods:] = p\n",
    "        # imput julian timesteps\n",
    "        hseqs.append(seq)\n",
    "        \n",
    "    training_data, training_labels, holdout_data, holdout_labels = np.array(tseqs,dtype='float64'),np.array(tlabels,dtype='float64'), np.array(hseqs,dtype='float64'),np.array(hlabels,dtype='float64')\n",
    "    print(\"training_data: {}, training_labels: {}, holdout_data: {}, holdout_labels: {}\".format(training_data.shape, training_labels.shape, holdout_data.shape, holdout_labels.shape))\n",
    "    return training_data, training_labels, holdout_data, holdout_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data configuration \n",
    "\n",
    "file_name = 'dataset_icu.csv'\n",
    "# time unit 15 minutes\n",
    "# length of time blocks\n",
    "freq=60\n",
    "# filter top %1 longest admission \n",
    "filter_outliers=True\n",
    "icu_df = data_formating(file_name,freq, filter_outliers)\n",
    "\n",
    "# sampling parameters\n",
    "start='last'\n",
    "duration=24\n",
    "dt_end=12\n",
    "j_block=freq\n",
    "\n",
    "random = slicing(icu_df,start,duration,dt_end,j_block)\n",
    "print('loaded successfully')\n",
    "\n",
    "#directory\n",
    "start='first24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit 15mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=15\n",
    "j_block=15\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=False\n",
    "medication=False\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df3,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_15Tr5.npy',training_data)\n",
    "np.save(start+'/tlabels_15Tr5.npy',training_labels)\n",
    "np.save(start+'/hseq_15Tr5.npy',holdout_data)\n",
    "np.save(start+'/hlabels_15Tr5.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=15\n",
    "j_block=15\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u15,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies,j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_15Tr10jd.npy',training_data)\n",
    "np.save(start+'/tlabels_15Tr10jd.npy',training_labels)\n",
    "np.save(start+'/hseq_15Tr10jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_15Tr10jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=15\n",
    "j_block=15\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u30,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_15Tr15jd.npy',training_data)\n",
    "np.save(start+'/tlabels_15Tr15jd.npy',training_labels)\n",
    "np.save(start+'/hseq_15Tr15jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_15Tr15jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=15\n",
    "j_block=15\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=True\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u60,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_15Tr_all.npy',training_data)\n",
    "np.save(start+'/tlabels_15Tr_all.npy',training_labels)\n",
    "np.save(start+'/hseq_15Tr_all.npy',holdout_data)\n",
    "np.save(start+'/hlabels_15Tr_all.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit 30mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=30\n",
    "j_block=30\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=False\n",
    "medication=False\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#random = slicing(icu_df3,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_30Tr5.npy',training_data)\n",
    "np.save(start+'/tlabels_30Tr5.npy',training_labels)\n",
    "np.save(start+'/hseq_30Tr5.npy',holdout_data)\n",
    "np.save(start+'/hlabels_30Tr5.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=30\n",
    "j_block=30\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u30,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_30Tr10jd.npy',training_data)\n",
    "np.save(start+'/tlabels_30Tr10jd.npy',training_labels)\n",
    "np.save(start+'/hseq_30Tr10jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_30Tr10jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=30\n",
    "j_block=30\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u30,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_30Tr15jd.npy',training_data)\n",
    "np.save(start+'/tlabels_30Tr15jd.npy',training_labels)\n",
    "np.save(start+'/hseq_30Tr15jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_30Tr15jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=30\n",
    "j_block=30\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=True\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u30,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_30Tr_all.npy',training_data)\n",
    "np.save(start+'/tlabels_30Tr_all.npy',training_labels)\n",
    "np.save(start+'/hseq_30Tr_all.npy',holdout_data)\n",
    "np.save(start+'/hlabels_30Tr_all.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit 60mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=60\n",
    "j_block=60\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=False\n",
    "medication=False\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df3,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_60Tr5jd.npy',training_data)\n",
    "np.save(start+'/tlabels_60Tr5jd.npy',training_labels)\n",
    "np.save(start+'/hseq_60Tr5jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_60Tr5jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=60\n",
    "freq=60\n",
    "# filter top %1 longest admission \n",
    "\n",
    "j_block=60\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=False\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=False\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u60,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_60Tr10jd.npy',training_data)\n",
    "np.save(start+'/tlabels_60Tr10jd.npy',training_labels)\n",
    "np.save(start+'/hseq_60Tr10jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_60Tr10jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=60\n",
    "j_block=60\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=False\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u60,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_60Tr15jd.npy',training_data)\n",
    "np.save(start+'/tlabels_60Tr15jd.npy',training_labels)\n",
    "np.save(start+'/hseq_60Tr15jd.npy',holdout_data)\n",
    "np.save(start+'/hlabels_60Tr15jd.npy',holdout_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#file_name = 'dataset_icu.csv'\n",
    "\n",
    "# length of time blocks\n",
    "freq=60\n",
    "j_block=60\n",
    "\n",
    "# julian time dummified\n",
    "dummies = True\n",
    "\n",
    "# features selection\n",
    "base=True\n",
    "vitals=True\n",
    "comments=True\n",
    "v_set=True\n",
    "medication=True\n",
    "notes=True\n",
    "n_extract=True\n",
    "\n",
    "# Data Pipeline\n",
    "#icu_df3 = data_formating(file_name,freq, filter_outliers)\n",
    "#last = slicing(icu_df_u60,start,duration,dt_end,j_block)\n",
    "cleaned = transformer(random,dummies, j_block,base,vitals,comments,v_set,medication,notes,n_extract)\n",
    "training_data, training_labels, holdout_data, holdout_labels = create_dataset(cleaned,freq)\n",
    "\n",
    "np.save(start+'/tseq_60Tr_all.npy',training_data)\n",
    "np.save(start+'/tlabels_60Tr_all.npy',training_labels)\n",
    "np.save(start+'/hseq_60Tr_all.npy',holdout_data)\n",
    "np.save(start+'/hlabels_60Tr_all.npy',holdout_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
